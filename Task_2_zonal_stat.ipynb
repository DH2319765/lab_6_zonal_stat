{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import necessary Modules -- pip install rasterio geopandas pandas rasterstats os logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from rasterstats import zonal_stats\n",
    "import os\n",
    "import logging ##-- i am trying a new approach to use logging to track what's happening in your code while it runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "## Source - stackoverflow.com/questions/50714316/how-to-use-logging-getlogger-name-in-multiple-modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 17:05:44,350 - INFO - Starting zonal statistics calculation...\n",
      "2024-11-18 17:05:44,352 - INFO - Reading vector file...\n",
      "2024-11-18 17:05:44,419 - INFO - Vector CRS: EPSG:32615\n",
      "2024-11-18 17:05:44,420 - INFO - Raster CRS: EPSG:32615\n",
      "2024-11-18 17:05:44,421 - INFO - Calculating zonal statistics...\n",
      "2024-11-18 17:05:49,483 - INFO - Processing results...\n",
      "2024-11-18 17:05:49,484 - INFO - Calculation completed successfully!\n",
      "2024-11-18 17:05:49,486 - INFO - \n",
      "Zonal Statistics Results:\n",
      "2024-11-18 17:05:49,490 - INFO - Results saved to: C:\\Aviskar_Portal\\Aviskar_Confidential\\Geospattia)_Analytics\\lab_6\\task_2\\zonal_stats_results.csv\n",
      "2024-11-18 17:05:49,490 - INFO - \n",
      "Summary Statistics:\n",
      "2024-11-18 17:05:49,494 - INFO - Total number of zones processed: 372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mean       std\n",
      "ID                    \n",
      "41  0.405855  0.067818\n",
      "42  0.406319  0.058588\n",
      "61  0.424627  0.065736\n",
      "62  0.417399  0.071759\n",
      "63  0.363553  0.140118\n",
      "             mean         std\n",
      "count  372.000000  372.000000\n",
      "mean     0.352218    0.104724\n",
      "std      0.047928    0.026245\n",
      "min      0.194923    0.042383\n",
      "25%      0.318571    0.088968\n",
      "50%      0.354612    0.105973\n",
      "75%      0.390165    0.117623\n",
      "max      0.444366    0.185824\n"
     ]
    }
   ],
   "source": [
    "##creating function step by step\n",
    "\n",
    "# no this is not chatgpt lol--i am doing it myself--First function to allign CRS\n",
    "\n",
    "def check_and_align_crs(vector_gdf, raster_path):\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs\n",
    "\n",
    "    # convert CRS to string format for comparison \n",
    "    vector_crs = str(vector_gdf.crs)\n",
    "    raster_crs = str(raster_crs)\n",
    "\n",
    "    logger.info(f\"Vector CRS: {vector_crs}\")\n",
    "    logger.info(f\"Raster CRS: {raster_crs}\")\n",
    "\n",
    "    if vector_crs != raster_crs:\n",
    "        logger.warning(\"CRS mismatch detected. Reprojecting vector data...\")\n",
    "        vector_gdf = vector_gdf.to_crs(raster_crs) ## --reprojecting if CRS mismatch occurs\n",
    "        logger.info(\"Reprojection completed\")\n",
    "    \n",
    "    return vector_gdf\n",
    "## acutal function to calucalte zonal_stats, -- I added id column as an input because different shapefiles/geojson files might use different column names as their unique identifier.\n",
    "\n",
    "def calculate_zonal_stats(raster_path, vector_path, id_column):\n",
    " \n",
    "    try:\n",
    "        # verify files exist\n",
    "        if not os.path.exists(raster_path):\n",
    "            raise FileNotFoundError(f\"Raster file not found: {raster_path}\")\n",
    "        if not os.path.exists(vector_path):\n",
    "            raise FileNotFoundError(f\"Vector file not found: {vector_path}\")\n",
    "            \n",
    "        # read the vector file\n",
    "        logger.info(\"Reading vector file...\")\n",
    "        gdf = gpd.read_file(vector_path)\n",
    "        \n",
    "        # verify the ID column exists\n",
    "        if id_column not in gdf.columns:\n",
    "            raise ValueError(f\"ID column '{id_column}' not found in the vector file\")\n",
    "        \n",
    "        # check and align CRS\n",
    "        gdf = check_and_align_crs(gdf, raster_path)\n",
    "            \n",
    "        # calculate zonal statistics\n",
    "        logger.info(\"Calculating zonal statistics...\")\n",
    "        stats = zonal_stats(gdf, \n",
    "                          raster_path,\n",
    "                          stats=['mean', 'std'],\n",
    "                          geojson_out=True)\n",
    "        \n",
    "        # convert to DataFrame\n",
    "        logger.info(\"Processing results...\")\n",
    "        result_df = pd.DataFrame([\n",
    "            {\n",
    "                'ID': feature['properties'][id_column],\n",
    "                'mean': feature['properties']['mean'],\n",
    "                'std': feature['properties']['std']\n",
    "            }\n",
    "            for feature in stats\n",
    "        ])\n",
    "        \n",
    "        # set ID as index\n",
    "        result_df.set_index('ID', inplace=True)\n",
    "        \n",
    "        logger.info(\"Calculation completed successfully!\")\n",
    "        return result_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # define paths\n",
    "    base_path = r\"C:\\Aviskar_Portal\\Aviskar_Confidential\\Geospattia)_Analytics\\lab_6\\task_2\"\n",
    "    raster_path = os.path.join(base_path, \"ndvi.tif\")\n",
    "    vector_path = os.path.join(base_path, \"grid.geojson\")\n",
    "    output_path = os.path.join(base_path, \"zonal_stats_results.csv\")\n",
    "    \n",
    "    # calculate zonal statistics\n",
    "    logger.info(\"Starting zonal statistics calculation...\")\n",
    "    results = calculate_zonal_stats(raster_path, vector_path, id_column='id')\n",
    "    \n",
    "    if results is not None:\n",
    "        logger.info(\"\\nZonal Statistics Results:\")\n",
    "        print(results.head(5))##--only taking top 5 results to show here. Check the csv file for full data\n",
    "        \n",
    "        # save results to CSV\n",
    "        results.to_csv(output_path)\n",
    "        logger.info(f\"Results saved to: {output_path}\")\n",
    "        \n",
    "        # basic statistics summary\n",
    "        logger.info(\"\\nSummary Statistics:\")\n",
    "        print(results.describe())\n",
    "        \n",
    "        logger.info(f\"Total number of zones processed: {len(results)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geowork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
